{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement learning on PyTorch to solve Open AI Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v1').unwrapped\n",
    "\n",
    "# setting matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_python:\n",
    "    from Ipython import Display\n",
    "    \n",
    "# check if gpu is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay memory will be used for training our DQN network which helps in storing the transitions the agent undergoes allowing us to make use of this data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('transition',('state','action','next_state','reward'))\n",
    "\n",
    "class ReplayMem(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        ## Save a transition\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Neural Network Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, h, w, out):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.total_actions = 3\n",
    "        self.gamma = 0.99\n",
    "        self.final_epsilon = 0.0001\n",
    "        self.initial_epsilon = 0.1\n",
    "        self.num_iterations = 2000000\n",
    "        self.replay_mem_size = 10000\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 5, stride = 2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 5, stride = 2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size = 5, stride = 2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc5(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ini_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        torch.nn.init.uniform(m.weight, -0.01, 0.01)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert image to tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_tensor(img):\n",
    "    img_tensor = img.transpose(2,0,1)\n",
    "    img_tensor = img_tensor.astype(np.float32)\n",
    "    img_tensor = torch.from_numpy(img_tensor)\n",
    "    #check if cuda is available\n",
    "    if torch.cuda.is_available():\n",
    "        img_tensor = img_tensor.cuda()\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing and colour to grey scale conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rgb2grey(img):\n",
    "    img = img[0:288, 0:404]\n",
    "    img_data = cv2.cvtColor(cv2.resize(image, (84,84)), cv2.COLOR_BGR2GRAY)\n",
    "    img_data[img_data > 0] = 255\n",
    "    img_data = np.reshape(img_data, (84,84,1))\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
